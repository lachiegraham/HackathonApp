<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Recorder</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin-top: 50px;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            margin: 10px;
        }
        p {
            text-align: center;
            padding: 10px 20px;
        }
    </style>
</head>
<body>

    <h1 id="wordToSay">Try to say: Rabbit</h1>

    <button id="startRecordBtn">Start Recording</button>
    <h3>Recorded Audio:</h3>
    <audio id="audioPlayback" controls></audio>

    <br/>
    <a id="downloadLink" style="display: none;">Download Recording</a>
    <br/>
    <br/>
    <p id="output1"></p>
    <p id="output2"></p>

    <script>
        const startRecordBtn = document.getElementById('startRecordBtn');
        const audioPlayback = document.getElementById('audioPlayback');
        const downloadLink = document.getElementById('downloadLink');
        const output1 = document.getElementById('output1');
        const output2 = document.getElementById('output2');
        const wordToSay = document.getElementById('wordToSay');
        let mediaRecorder;
        let audioChunks = [];

        let wordsList = ["Rabbit", "Buffalo", "Calendar", "Violin"];

        startRecordBtn.addEventListener('click', async () => {
            // If we are recording, stop the recording
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop();
                requestAnalysisStart();
                return;
            }
            // else, start the recording
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);

            mediaRecorder.onstart = () => {
                audioChunks = [];
                startRecordBtn.innerText = 'Stop Recording';
            };

            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                audioPlayback.src = audioUrl;
                downloadLink.href = audioUrl;
                downloadLink.download = 'recording.wav';
                downloadLink.style.display = 'block';

                startRecordBtn.innerText = 'Analysing';
                startRecordBtn.disabled = true;
            };

            mediaRecorder.start();
        });

        async function requestAnalysisStart() {
            await new Promise(r => setTimeout(r, 1000));
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            await main(audioBlob);
        }


        async function main(audioBlob) {
            const formData = new FormData();
            formData.append("file", audioBlob, "recording.wav");

            const response = await fetch("https://api.lemonfox.ai/v1/audio/transcriptions", {
                method: "POST",
                headers: {
                    "Authorization": `Bearer OKnZjjk0Ww2fQCiY7nW4hmYXhh6aJJog`, // Replace with your actual API key
                },
                body: formData,
            });

            if (!response.ok) {
                console.error("Error:", response.statusText);
                return;
            }

            const transcription = await response.json();
            console.log(transcription.text);

            if (transcription.text === "Rabbit." || transcription.text === "Rabbit") {
                output1.textContent = "You Said it correctly!";
            } else {
                output1.textContent = "You said it incorrectly";

                const gptResponse = await fetch('https://api.lemonfox.ai/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer OKnZjjk0Ww2fQCiY7nW4hmYXhh6aJJog`, // Replace with your actual API key
                    },
                    body: JSON.stringify({
                        model: 'gpt-3.5-turbo',
                        messages: [{ role: 'user', content: 'Give me instructions within 2 sentences on how to correct my pronunciation, including specific instructions for my tongue positioning, I am trying to say Rabbit, but instead I say'.concat(transcription.text)}],
                    }),
                });

                if (!gptResponse.ok) {
                    console.error('Error:', gptResponse.statusText);
                    return;
                }

                const data = await gptResponse.json(); // Correctly using gptResponse
                const gptAnswer = data.choices[0].message.content;
                output2.textContent = gptAnswer;
            }
        }
    </script>
</body>
</html>
